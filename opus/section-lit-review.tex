\documentclass[main.tex]{subfiles}
\begin{document}

\section{History and Similar Efforts}

Automated document classification has been a highly productive area of study in the fields of text mining and machine learning. Initial attempts at document classification, and automated classification in general, were in the form of expert systems. Expert systems consist of human-compiled rules which are applied to a particular instance, such as a document, and make decisions about that instance based on occurrences of predefined features \citep{clifford:1983}. Such a system relies entirely on the knowledge of the human expert who compiles the rules. The goal of such a system is to automate the classification process but not necessarily to classify any more accurately than might an expert human. While such a system can theoretically approach the accuracy of the human who compiled the rules, it is incapable of exceeding that accuracy, and it comes at a high cost in terms of development time. Early attempts to solve these problems, in particular the latter, explored the automated creation of rule sets. \citet{apte:1994} was an early study into the effectiveness of computer-generated rule sets. Because of the enormous time savings afforded by such a system, and because of the potential of such systems to exceed the accuracy of humans, classification systems using computer-generated rule sets have become very common in commercial products (consider, for instance, spam email filtering \citep{cormack:2008}) and continue to be a very active area of research. The reader who desires a more detailed account of the history of document classification and a survey of its current (as of 2004) state is referred to \citet{berry:2004}.

One of the goals of the current study is to explore how a text classification system can be used to develop a software tool which provides suggestions to language learners on how they can improve their written language. In light of that, it is worth exploring similar existing tools. Grammar checkers are one such tool. A great deal of work has been done in the field of automatic grammar checking and, in many ways, this is a very mature field of computer science. English grammar checkers have been available in commercial word processors for nearly two decades \citep{vernon:2000}, and there has been much progress, recently, on grammar checkers targeted towards language learners. One such effort is Microsoft Research's ESL Assistant. One element of this system, described in \citet{gamon:2010}, focuses on identifying common learner errors in article and preposition usage. The system uses maximum entropy classifiers in a novel approach to determine whether a particular location in a text should have an article or preposition and, if so, which specific article or preposition. The system looks at word boundaries within the text. For each boundary, it gathers features from the six words to the right and left of the boundary. It then applies the first of two classifiers to this feature set. The \textit{presence classifier} determines the probability that the boundary is an appropriate location for an article or preposition. Then, if a location with a high probability is identified, a second classifier, the \textit{choice classifier}, is applied to this set of features to identify the most likely appropriate articles or prepositions for use in that location. The system then compares the results of the classifiers with any articles or prepositions actually used in that location, and makes suggestions to the user. One benefit of this approach is that the classifiers need only be trained on native texts, which are more plentiful than nonnative texts. The study also explains how meta-classifiers can be used to improve upon this approach. For this, a second error detection system is used as well, based on language models. Language models are systems that assign a probability to a sequence of words, indicating how likely it is for that sequence of words to occur in natural language. Gamon then uses both of these error detection systems as part of a meta-classifier trained on a corpus of learner texts in which all preposition and article errors have been marked. He finds that the meta-classifier provides considerably better accuracy than either system used alone.

\citet{lee:2006} explore a generative approach to grammar correction for language learners. In this system, one sentence or utterance is processed at a time. A number of permutations on the input are produced by modifying articles and prepositions, inflecting nouns and verbs, and swapping auxiliary verbs. A language model is then used to choose a small subset of these permutations as candidates for correction. The study used both human evaluators and automatic evaluators to determine whether the system was producing output more appropriate than the learner's input.

\citet{wagner:2007} compare two automated grammatical error detection systems. Though the approaches they describe are not specific to learner English, the nature of the systems do make them well suited for such. The first approach they describe uses a \textit{precision grammar}. A precision grammar is a set of grammatical rules (see chapter ``Parsing and Classification'') designed to parse only strictly grammatical language. This is in contrast to the grammars used in general purpose parsers, which tend to be designed to accommodate common errors. In this approach, the precision grammar is used to identify errors (i.e., unparseable passages). Though this study does not focus on providing corrections, the authors note that it is possible to include special ``mal-rules'' to identify specific types of malformed syntax. The second approach \citeauthor{wagner:2007} explore uses part of speech \textit{n}-grams (considering only the parts of speech of sequences of words) with language models to identify grammatical errors.

The studies highlighted here are a small sample of the work that has been done in the areas of automated grammatical error detection and correction, but they are representative of the two most common approaches used: a shallow approach, using language models and \textit{n}-grams to identify errors; and a deep approach, using parsers. The technologies used to generate corrections are more varied, and the reader interested in a broader review is referred to \citet{lee:2009}.

Little or no research has been done towards a system based on distinguishing native English from well-formed nonnative English, nor directly towards a system that offers grammatical suggestions to improve already grammatical learner English. It is likely that a system using language models could be adapted towards these ends, though that is not the approach taken here. Most of the work done on providing automatic grammar evaluation has been focused on the routine grammatical errors made by native speakers, or on the errors typical of novice and intermediate English learners. There appears to be little in the way of automated tools for advanced learners who wish to bring their writing skills to near-native levels of proficiency.


\biblio
\end{document}