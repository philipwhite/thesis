\documentclass[main.tex]{subfiles}
\begin{document}

\section{Introduction}
\setcounter{section}{1}
Fluency is the goal of most language learners. While mastering the spoken language is usually the primary goal, becoming a proficient writer is of importance to many learners, particularly those who learn languages for professional or academic reasons. Although it is generally less obvious than in the case of spoken language, most learners will reach a stage when they produce language which is grammatically correct but which is still identifiable as nonnative. At this stage, further improvement of their language is no longer a matter of error correction but of changing subtleties in their production which may not be apparent to the learner. A learning tool that could analyze written language and give feedback to the user on which aspects of his or her language need to be modified to reach a native level would be useful. Such a tool would only be possible if there existed an automated system that could analyze language, classify it as native or nonnative, and give the reasons for the classification. This paper describes such a system.

Most computer-based ESL tools have been meant for beginning and intermediate learners and thus focus on grammatical mistakes. Such tools analyze text and offer suggestions on aspects such as correct article usage or noun pluralization. In many ways, these tools are very similar to the grammar checkers found in most modern word-processing packages, though those tend to be targeted towards native speakers or towards no particular group of users. In general, these tools are not of any use in the analysis of syntactically well-formed text.

\begin{comment}
The classification of text documents is a fairly mature technology, often used in categorizing medical and business documents. Little work has been done in applying this technology to second language learning.
\end{comment}

The system explored in this study relies on modern language parsing systems. Probabilistic parsers are capable of generating grammatical parse trees of texts in a number of languages, particularly English, with a high degree of accuracy. Such systems, such as the Stanford Parser, used in this study, are often capable of presenting additional syntactic information in the form of dependency graphs, which indicate various relationships between words. This study uses automatically generated parse trees and dependency graphs to identify grammatical features. The relative frequencies of all features are calculated, and this information is used to train automatic classifiers, which are then tested on other text samples. 

The next chapter of this paper is a literature review and a description of similar and relevant existing technologies. The third chapter describes the corpora from which the text samples were gathered. The fourth chapter gives a brief description of the parsing and classification systems used and describes the general experimental setup used in this study. The next three chapters describe the three experiments performed. Each of these experiments deals with a different set of grammatical features. These chapters describe the methods by which each set of grammatical features is extracted from the output of the Stanford Parser, and they analyze the effectiveness of classifiers trained on these features. Two of these experiments further break down feature sets into smaller coherent subsets to ease in the analysis of their efficacy. In these three chapters, the decision trees generated by the classifiers are also analyzed to identify the linguistic significance of the features used in the trees. Finally, in the eighth chapter, this paper proposes a design for a learner's tool based on this system and suggests other possible applications as well.

\biblio
\end{document}