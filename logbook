25 July '11
Added file train_deps.clj to contain code for running the deps-based classification. Using clj-ml to interface weka.
Began initial test by constructing a Weka data set with as many attributes as there are stanford dependencies (50 some). I added a weka Instance to the data set for each sample text. I setup each attribute to be numeric, counting the number of times a particular dependency relation is used in a text (i.e. just the basic dep such as "xsubj", ignoring the words that are parameters), dividing that number by the total number of dependencies and using that as the attribute value. Class attribute has the key "L1" with possible values "en" or "es".
thesis.train-deps/make-reln-dataset-with-samples will construct the weka dataset from the supplied list of english and spanish L1 micusp files.
Starting a run with 8 L1 spanish and 9 L1 english texts. Following run need to train a classifier.

20 July '11
10:05PM
Renamed parser.clj to parse.clj along with package thesis.parse. This packages now contains a function parse-sentences that takes a list of preprocessed text and returns only the parses that are complete sentences. Also added functions in data.clj that return the preprocessed text. Next step is to write a function that will create dependences for these parses. Then use those dependencies as features for WEKA.

2:29PM
Finished a preliminary preprocessor for the micusp resource. regexes need improvement as some documents seem to be cutoff. Also there is some initial information that needs to be striped.

18 July '11 10:41PM
Have been working on a preprocessor for the micusp resource. Still in progress. There are slight differences between the files in terms of the page headers that need to be stripped; mainly a difference of newlines but possibly more. New folder code-nu containing code that does batch converts from PDFs to utf8.

17 July '11
1:41PM
NB: MICUSP: Michigan Corpus of Upper-Level Student Papers
http://search-micusp.elicorpora.info/simple/

1:24PM
Downloaded ice-canada corpus. Zip file (in data/ice-canada/) is password protected. etc/ICElicence.doc needs to be completed and emailed after July '11 (researcher is out of town).
http://ICE-corpora.net/ice/download.htm

13 July '11 9:32PM
Setup remote git repository for this project at thesis@rivulus-sw.com:thesis

12 July '11 3:16PM
Initial entry. Up to this point, I have been
working in Clojure with the Stanford Parser (1.6.4 and now
1.6.7). Using the factored and PCFG parser I have generated
parse-trees and Stanford dependencies.
Yesterday spoke to Drs. Biava
and Smith regarding this project. Basically just explained my
intentions. Talked about finding corpora, the surprising paucity of
Spanish linguistics literature, etc.

I should provide a basic overview of my goals here:
Using parse trees, Stanford Dependencies, possibilty vocabulary, and a
machine learning package (likely WEKA) I want to create a system that
will look at an English text and attempt to determine if it was
written by a Spanish L1 or native English speaker. The problem here if
finding the features in trees etc. that will allow this
classification.

Immediate Plans:
Setup a Git repository? Today I emailed Dr. Smith regarding university
server space for this.
Stanford dependencies consists of "approximately 52 grammatical
relations" (SD manual). Try using these as features for a first
attempt at a classifications system. In other words, for a text just
count the number of each relation it has and see if that gives the
classifier something to work with.

Relevent Works:
-For the PCFG parser: Dan Klein and Christopher
D. Manning. 2003. Accurate Unlexicalized Parsing. Proceedings of the
41st Meeting of the Association for Computational Linguistics,
pp. 423-430. 
-For the factored parser: Dan Klein and Christopher
D. Manning. 2003. Fast Exact Inference with a Factored Model for
Natural Language Parsing. In Advances in Neural Information Processing
Systems 15 (NIPS 2002), Cambridge, MA: MIT Press, pp. 3-10.